# Q-Learning-GridWorld
Reinforcement Learning in a 5×5 Environment

---

🧠 **Learning to Navigate with Q-Learning**  
This is a Mathematica-based project where I implemented **Q-Learning** in a simple **5×5 grid-world**.  
The goal was to see how an agent can discover an optimal path to a target while avoiding obstacles — starting from scratch, with no prior knowledge of the environment.  

Instead of black-box frameworks, everything here is **built from the ground up**: state definitions, reward structures, Q-updates, and visualizations.  
The emphasis is on understanding the mechanics of reinforcement learning rather than just applying a library.

---

## 📂 What’s Inside

### Core Notebook
- **QLearning_GridWorld.nb** — Complete implementation of the grid-world navigation problem in Mathematica:  
  - Environment setup (states, obstacles, start, goal)  
  - Q-Learning algorithm (with α, γ, ε tuning)  
  - Reward structure design  
  - Training loop and convergence tracking  
  - Visualization of the learned path  

### Notes & Documentation
- **q-learning-gridworld.pdf** — Short write-up covering:  
  - Reward shaping in small environments  
  - How ε-greedy exploration balances exploration vs exploitation  
  - Why convergence can be achieved in under 100 episodes in this setup  

---

## 📌 Highlights
- Designing rewards that encourage efficient navigation  
- Deriving and applying the **Q-update rule** step by step  
- Watching the agent gradually “discover” the optimal route  
- Demonstrating convergence in <100 episodes  
- Using Mathematica as both a **symbolic tool** and a **simulation engine**  

---

## 🎯 Who This Is For
If you’re learning **reinforcement learning fundamentals**, want a compact example of **Q-learning in Mathematica**, or just curious about how simple agents can learn optimal paths in toy environments, this should help.  

It’s especially useful if you prefer step-by-step derivations and transparent code rather than just relying on Python RL libraries.

---

## 🛠 Tools Used
- **Mathematica** — for implementation, visualizations, and symbolic checks  
- **Custom reward structure** — designed for balancing goal-reaching, obstacle avoidance, and step minimization  

---

## 📬 Contact
If you’re exploring reinforcement learning, symbolic computation, or want to discuss grid-world experiments:  

📧 **vimals24@iitk.ac.in**  

---

*"In small grids, big ideas grow — Q-learning shows how even the simplest agents can learn through trial, error, and persistence."*
